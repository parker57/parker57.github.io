<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Parker57.GitHub.io : Lego Robot Challenge (LRC) and Virtual Robot Simulator (VRS)">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Parker57.GitHub.io</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/parker57">View on GitHub</a>

          <h1 id="project_title">Parker57.GitHub.io</h1>
          <h2 id="project_tagline">Lego Robot Challenge (LRC) and Virtual Robot Simulator (VRS)</h2>

        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        
<!--<h3><a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Welcome to GitHub Pages.</h3>-->
          
        <h2>Lego Robot Challenge (LRC)</h2>
        
<h3>
  Week 4: [24/10/2016-28/10/2016]</h3>
<p>Towards the culmination of the Lego Robot Challenge, the group decided to use the touch sensor to prevent the robot from advancing over the edge of the arena. The touch sensor read a binary value, with 1/High reading as the touch sensor being pressed and there for permitting the robot to proceed. A 0/Low reading resulted in a simultaneous termination and initiation of the code block, which rotated the large wheels forwards, and one which reversed course respectively. An exhibition of this behaviour can be seen in the GIF below.</p>       
<img src="images/gif response to edge.gif" alt="Gif of touch sensor in action.">
<p>Here is the side view, a flipper attached to a small motor was our robots means of defence, it was triggered when the heat sensor detected another robot in the proximity. The hear/proximity sensor is the large bulb suspended from the crane attached to the left wheel rack.
<br>
A colour sensor was attached to the rear, It's behaviours mirrored the touch sensor. As the arena had a thick white line as a perimeter, the programme set the robot to advance when he colour sensor read white.
        </p> 
<img src="images/exact side n.jpg" alt="Gif of touch sensor in action.">
<p>If you prefer to not use the automatic generator, push a branch named <code>gh-pages</code> to your repository to create a page manually. In addition to supporting regular HTML content, GitHub Pages support Jekyll, a simple, blog aware static site generator. Jekyll makes it easy to create site-wide headers and footers without having to copy them across every page. It also offers intelligent blog support and other advanced templating features.</p>
images/exact side n.jpg
<h3>Week 2: [10/10/2016-14/10/2016] - Week 3: [17/10/2016-21/10/2016]</h3>
        <p>
After several project sessions and a few scrum meetings, the EV3 brick had successfully been attached to the base, was communicating reliably with the components and I was sufficiently fluent with the proprietary visual programming language to command the robot to respond appropriately to various inputs and stimuli. Attention was then turned to how best utilise the components such as the motors and sensors.<br>
Bluetooth was experimented with using both Lego's own app and a popular app: 'EV3 Simple Remote'. The value of implementing Bluetooth communication was limited by the fact the brief required us to create a programme and machine which could work autonomously, independent of further user input.<br>
This being said, the Bluetooth messaging block in Lego's Visual programming language was useful for testing the readings of the sensors to determine how well calibrated our programmes were for their sensitivities. 
        </p>
          
<h3>Week 1: [03/10/2016-07/10/2016]</h3>

<p>Intro to Activity-Led Learning (ALL). Introduction to the group. We familiarised ourselves with the equipment provided and verified that it matched the inventory on the Equipment Loan Sheet. <br>After introductions we began tinkering with the components. We agreed to model out robot after TRACK3R for its simplicity. Eventually we constructed a bed to mount the Programmable Brick onto. Two large motors were attached to the wheel axles either side. After that we familiarised ourselves with the Lego visual programming language and were able to get the brick to run some very basic programmes.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
